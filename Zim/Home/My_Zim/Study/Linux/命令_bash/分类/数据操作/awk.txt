Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2017-12-01T08:12:57+08:00

====== awk ======
Created Friday 01 December 2017

awk


-F 分隔符 以分隔符分隔内容
{} 要执行的脚本内容 eg:cat /etc/passwd |awk -F ':' '{print $1"\t"$7}'

最好的留在最后。awk 不仅仅是一个简单的命令：它是一个成熟的语言。在本文中涉及的所有内容中，awk 是目前为止最酷的。如果你感兴趣，这里有很多很棒的资源 —— 看 这里[6]、这里[7] 和 这里[8]。

awk 的常见用例包括：

__文字处理__
__格式化文本报告__
__执行算术运算__
__执行字符串操作__
awk 可以以最原生的形式并行 grep。

awk '/word/' filename.csv
或者更加神奇：将 grep 和 cut 组合起来。在这里，对于所有带我们指定单词 word 的行，awk 打印第三和第四列，用 tab 分隔。-F, 用于指定切分时的列分隔符为逗号。

awk -F, '/word/ { print $3 "\t" $4 }' filename.csv
awk 内置了许多精巧的变量。比如，__NF —— 字段数__，和 __NR —— 记录数__。要获取文件中的第 53 条记录：

awk -F, 'NR == 53' filename.csv
更多的花招是其基于一个或多个值进行过滤的能力。下面的第一个示例将打印第一列等于给定字符串的行的行号和列。

awk -F, ' $1 == "string" { print NR, $0 } ' filename.csv

# Filter based off of numerical value in second column
awk -F, ' $2 == 1000 { print NR, $0 } ' filename.csv
多个数值表达式：

# Print line number and columns where column three greater
# than 2005 and column five less than one thousand

awk -F, ' $3 >= 2005 && $5 <= 1000 { print NR, $0 } ' filename.csv
求出第三列的总和：

awk -F, '{ x+=$3 } END { print x }' filename.csv
在第一列等于 something 的那些行，求出第三列值的总和。

awk -F, '$1 == "something" { x+=$3 } END { print x }' filename.csv
获取文件的行列数：

awk -F, 'END { print NF, NR }' filename.csv

# Prettier version
awk -F, 'BEGIN { print "COLUMNS", "ROWS" }; END { print NF, NR }' filename.csv
打印出现了两次的行：

awk -F, '++seen[$0] == 2' filename.csv
删除重复的行：

# Consecutive lines
awk 'a !~ $0; {a=$0}']

# Nonconsecutive lines
awk '! a[$0]++' filename.csv

# More efficient
awk '!($0 in a) {a[$0];print}
使用内置函数 gsub() 替换多个值。

awk '{gsub(/scarlet|ruby|puce/, "red"); print}'
这个 awk 命令将组合多个 CSV 文件，忽略标题，然后在最后附加它。

awk 'FNR==1 && NR!=1{next;}{print}' *.csv > final_file.csv
需要缩小一个庞大的文件？ awk 可以在 sed 的帮助下处理它。具体来说，该命令根据行数将一个大文件分成多个较小的文件。这个一行脚本将增加一个扩展名。

sed '1d;$d' filename.csv | awk 'NR%NUMBER_OF_LINES==1{x="filename-"++i".csv";}{print > x}'

# Example: splitting big_data.csv into data_(n).csv every 100,000 lines
sed '1d;$d' big_data.csv | awk 'NR%100000==1{x="data_"++i".csv";}{print > x}'
