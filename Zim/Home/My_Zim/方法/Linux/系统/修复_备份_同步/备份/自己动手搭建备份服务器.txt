Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2019-06-06T11:44:07+08:00

====== 自己动手搭建备份服务器 ======
创建日期 星期四 06 六月 2019

https://zhuanlan.zhihu.com/p/53612691?utm_source=com.youdao.note&utm_medium=social&utm_oi=33829276352512
11.Back up your work! You can avoid many tears by doing this at least weekly.
（译：备份你的工作！保证至少每周一次备份可以避免追悔莫及的尴尬局面）
——引用自 Nature 20 things for a PhD
上面这句话是最近很火的一个已毕业的PhD给在读PhD的20个建议中的第11条，意思就是说【备份很重要】

目前商用的在线存储文件云有很多，这里不一一列举，多数是有免费额度的，但是免费额度又不大够用，有时候限速又限量。氪金是个好主意，但是这个东西其实还是有一定风险的，比如说很多东西是涉密的不能传上公网，有些东西特别大，同步起来很麻烦，等等



所以这里就有了我们自己造车的需求，自己做一个文件云服务。


需求

希望它可以有：

（1）最基本的支持加密协议（ssl），保证我存的东西在上传下载过程中是安全的

（2）支持文件分享，生成分享链接之后别人可以下载

（3）最好能有用户制度，这样做一个服务器可以实验室一起用

（4）有一个比较好看的界面，最好能有安卓 iOS 和桌面APP

（5）存储方便扩展（有朝一日老子有钱了加一堆硬盘）

（6）硬盘最好是阵列，这样炸了一个，还是有完整的文件，赶紧换上另外一个就行

（7）自建云服务最好放在局域网内，通过交换机直连，文件同步速度至少千兆吧



本文介绍搭建一个可以满足以上所有需求的备份服务器的从软件到硬件的完整过程

原料：

【*】硬盘若干（推荐某宝日立3T二手硬盘，是找了一圈下来性价比最高的硬盘，属于服务器升级换下来的，硬盘这个东西本身就是消耗品，买多贵的硬盘都有坏的一天，我们的容灾逻辑在阵列上，坏了在换就对了，反正我到现在为止还没跑炸过硬盘）


【*】阵列卡一张（推荐H200二手阵列卡，还送一转4的sata线）如果主板上sata口够的话就不用阵列卡了


【*】4口千兆交换机（40-300元不等，我买的是40的，对，压缩一切成本，实现最高性价比）


【*】一台闲置主机，这个对性能没有任何要求，多老的主机都没问题，只要有网口有PCIE插槽就行



所以合计一下：

硬盘 二手日立3T*4 【RMB 1200左右】

Raid卡 H200 以及1转4 SATA线 【RMB 200左右】

4口千兆交换机 【RMB 42】

旧主机【RMB 不要钱，跟师兄敲的】

总计：不到1500+请师兄一顿烧烤



组装：

可能你的旧主机像我一样没有硬盘空间了，你可以像我一样把硬盘放在外面。挂个小功率风扇防止积热，没有任何噪音。


然后把SATA线和硬盘电源线从机箱里伸出来，硬盘电源线不够长所以在机箱上打了个孔。。。



软件：

装机结束就是装软件了，首先是系统，装个你喜欢的linux发行版，不用win是为了可以稳定运行几十天不重启不死机，老电脑也吃得消。至于发行版大家就选自己喜欢的发行版就可以了我用ubuntu。


上一次更新内核重启到现在110天了，丝滑流场的运行文件备份服务，很稳。



系统装完之后，我们要建立磁盘阵列了，之前提到我们有四个硬盘，组一个raid5，也就是有三个盘的容量。 如果有任何一个坏了，系统会提示阵列坏了，此时赶紧替换下来坏的硬盘就好了。【这个就是所谓的容灾】



关于阵列方式具体是raid 0 1 5 6 10 怎么选可以参考一下网上关于磁盘阵列的介绍，这里给出一个benchmark。

			ZFS Raid Speed Capacity and Performance Benchmarks
				   (speeds in megabytes per second)

 1x 4TB, single drive,          3.7 TB,  w=108MB/s , rw=50MB/s  , r=204MB/s 
 2x 4TB, mirror (raid1),        3.7 TB,  w=106MB/s , rw=50MB/s  , r=488MB/s 
 2x 4TB, stripe (raid0),        7.5 TB,  w=237MB/s , rw=73MB/s  , r=434MB/s 
 3x 4TB, mirror (raid1),        3.7 TB,  w=106MB/s , rw=49MB/s  , r=589MB/s 
 3x 4TB, stripe (raid0),       11.3 TB,  w=392MB/s , rw=86MB/s  , r=474MB/s 
 3x 4TB, raidz1 (raid5),        7.5 TB,  w=225MB/s , rw=56MB/s  , r=619MB/s 
 4x 4TB, 2 striped mirrors,     7.5 TB,  w=226MB/s , rw=53MB/s  , r=644MB/s 
 4x 4TB, raidz2 (raid6),        7.5 TB,  w=204MB/s , rw=54MB/s  , r=183MB/s 
 5x 4TB, raidz1 (raid5),       15.0 TB,  w=469MB/s , rw=79MB/s  , r=598MB/s 
 5x 4TB, raidz3 (raid7),        7.5 TB,  w=116MB/s , rw=45MB/s  , r=493MB/s 
 6x 4TB, 3 striped mirrors,    11.3 TB,  w=389MB/s , rw=60MB/s  , r=655MB/s 
 6x 4TB, raidz2 (raid6),       15.0 TB,  w=429MB/s , rw=71MB/s  , r=488MB/s 
10x 4TB, 2 striped 5x raidz,   30.1 TB,  w=675MB/s , rw=109MB/s , r=1012MB/s 
11x 4TB, raidz3 (raid7),       30.2 TB,  w=552MB/s , rw=103MB/s , r=963MB/s 
12x 4TB, 6 striped mirrors,    22.6 TB,  w=643MB/s , rw=83MB/s  , r=962MB/s 
12x 4TB, 2 striped 6x raidz2,  30.1 TB,  w=638MB/s , rw=105MB/s , r=990MB/s 
12x 4TB, raidz (raid5),        41.3 TB,  w=689MB/s , rw=118MB/s , r=993MB/s 
12x 4TB, raidz2 (raid6),       37.4 TB,  w=317MB/s , rw=98MB/s  , r=1065MB/s 
12x 4TB, raidz3 (raid7),       33.6 TB,  w=452MB/s , rw=105MB/s , r=840MB/s 
22x 4TB, 2 striped 11x raidz3, 60.4 TB,  w=567MB/s , rw=162MB/s , r=1139MB/s 
23x 4TB, raidz3 (raid7),       74.9 TB,  w=440MB/s , rw=157MB/s , r=1146MB/s
24x 4TB, 12 striped mirrors,   45.2 TB,  w=696MB/s , rw=144MB/s , r=898MB/s 
24x 4TB, raidz (raid5),        86.4 TB,  w=567MB/s , rw=198MB/s , r=1304MB/s 
24x 4TB, raidz2 (raid6),       82.0 TB,  w=434MB/s , rw=189MB/s , r=1063MB/s 
24x 4TB, raidz3 (raid7),       78.1 TB,  w=405MB/s , rw=180MB/s , r=1117MB/s 
24x 4TB, striped raid0,        90.4 TB,  w=692MB/s , rw=260MB/s , r=1377MB/s 
综合以上来看，我们在有四个硬盘的时候，考虑到读写性能和安全性，还是选择raid5



安装ZFS并创建raid5的命令如下：

sudo zpool create -f [存储池名字] raidz /dev/sdb /dev/sdc /dev/sdd
这里raidz指的就是raid5的逻辑。

后面跟的/dev/sd*是指卷标，运行命令之前需要用fstab命令确定卷标是对的。



创建可能需要一段时间，创建之后可以输入zpool status 查看创建的结果：


如果是这样的，那就说明创建成功。



有了存储池（巨大的存储池），就是用这个存储池来学习实现我们的文件云，这里用到的软件是nextcloud：


这是一个开源的软件，所以不用担心有后门，或者是它会偷偷上传你的文件，以及官方偷看你的隐私之类的情况。

而且它有安卓和iOS的app，安装了app就可以愉快的在私人云上同步自己的照片和文件了。



安装nextcloud是有点麻烦，但是官网说的也是很清楚了。懒得看英文的可以跟着下面这个教程走一下。

Ubuntu Server 16.04一步一步手动安装NextCloud私有云
​
blog.csdn.net
图标
安装完nextcloud我们就成功的拥有了一个7.6T的可以容灾的文件云，这个文件云可以在线访问（通过Web的方式）


这里值得一提的是外部访问，这个非常取决于你的单位有没有给你一个独立IP。

如果你能在墙上找到一个提供独立IP的网口，那这个事情就非常好办了，首先要知道自己的IP是啥，这个只要百度【IP】字段，就会出现你的IP。ifconfig命令有时候给出的是局域网IP，比如


192.168.1.* 这个说明过路由器了。

这个时候想要从外网访问的话需要再路由器上设置端口转发(以我的NETGEAR路由器为例)：

先登陆到192.168.1.1（路由器的IP）：

从主机名判断是哪个设备在运行云盘服务


然后把文件云所服务的端口转发到对应的内网IP上，这里是我的路由表，可以看到有很多其他的服务，不同的端口代表不同的服务类型，被路由到不同的内部IP（192.168.1.*）对应不同的设备


安装的时候需要设置的服务端运行的端口，就转发这个端口就行了，这里我用4443端口。需要注意的是一般不要用80端口，80端口是http协议默认端口，一般用于网站，如果在公网上使用80端口需要备案。而且80端口也不安全，易受攻击



访问网盘的时候需要用你的【IP：端口号】 的形式来访问，如下


nextcloud也有手机和电脑的客户端。

电脑上可以设置同步区域，在同步区域里的文件，一但修改，这个修改就会传播到所有同步了这个文件夹的主机上，这是个极其优秀的feature，也就是说在办公室做了个PPT，回到寝室打开主机，只要连了网，再打开这个PPT可以接着之前在实验室没做完的继续做，这是一件多么美妙的事情。



而且可以很方便的设置账户，一人装机，全实验室用。


在有千兆交换机的内网下，文件同步简直闪电，这边一保存，那边打开笔记本锁屏，直接就提示文件已同步，这种丝滑的感觉真是会让你感觉这1500没白花。



最重要是


要多大，有多大，装多少硬盘就有多大



哈哈哈哈哈哈哈



这些东西确实有些开销，但是这是给科研和工作的开销，是正经的开销（一脸正经，理直气壮）
